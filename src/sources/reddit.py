import logging
import asyncio
from typing import List, Dict, Any, Optional
import aiohttp
import xml.etree.ElementTree as ET
import re
from bs4 import BeautifulSoup
import hashlib # Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ ID Ù…Ù†Ø­ØµØ± Ø¨Ù‡ ÙØ±Ø¯ Ø¨Ø±Ø§ÛŒ Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ ÙØ±Ø¹ÛŒ

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡ Ù„Ø§Ú¯â€ŒÚ¯ÛŒØ±ÛŒ
logging.basicConfig(
    level=logging.INFO, # Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§ÛŒÙ† Ø±Ø§ Ø¨Ù‡ logging.DEBUG ØªØºÛŒÛŒØ± Ø¯Ù‡ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ Ø¨Ø³ÛŒØ§Ø± Ø¬Ø²Ø¦ÛŒ
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

# Ø§ÛŒØ¬Ø§Ø¯ ÛŒÚ© Ù„Ø§Ú¯Ø± Ø®Ø§Øµ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ù…Ø§Ú˜ÙˆÙ„
logger = logging.getLogger(__name__)

class RedditSource:
    """
    Ú©Ù„Ø§Ø³ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø¨Ø§Ø²ÛŒâ€ŒÙ‡Ø§ÛŒ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø§Ø² Ø·Ø±ÛŒÙ‚ ÙÛŒØ¯ RSS Ø±Ø¯ÛŒØª.
    Ø§ÛŒÙ† Ù†Ø³Ø®Ù‡ Ù†ÛŒØ§Ø²ÛŒ Ø¨Ù‡ Ú©Ù„ÛŒØ¯ API Ù†Ø¯Ø§Ø±Ø¯ Ùˆ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ù‡ Ø¯Ø±Ø³ØªÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    def __init__(self):
        self.subreddits = [
            'GameDeals',
            'FreeGameFindings',
            'googleplaydeals',
            'AppHookup'
        ]
        # Ø°Ø®ÛŒØ±Ù‡ Ø³Ø§Ø¨â€ŒØ±Ø¯ÛŒØªâ€ŒÙ‡Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¢Ø³Ø§Ù† Ø¨Ù‡ Ù†Ø§Ù… Ùˆ URL
        self.rss_urls = {sub: f"https://www.reddit.com/r/{sub}/new/.rss" for sub in self.subreddits}
        logger.info("Ù†Ù…ÙˆÙ†Ù‡ RedditSource (Ù†Ø³Ø®Ù‡ RSS Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡) Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯.")

    @staticmethod
    def _generate_unique_id(base_id: str, item_url: str) -> str:
        """
        ÛŒÚ© ID Ù…Ù†Ø­ØµØ± Ø¨Ù‡ ÙØ±Ø¯ Ø¨Ø±Ø§ÛŒ Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ ÙØ±Ø¹ÛŒ Ø¯Ø± Ù¾Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ù„ÛŒØ³Øªâ€ŒÙ…Ø§Ù†Ù†Ø¯ ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
        """
        # Ø§Ø² Ù‡Ø´ SHA256 Ø¨Ø±Ø§ÛŒ Ø§ÛŒØ¬Ø§Ø¯ ÛŒÚ© ID Ù…Ù†Ø­ØµØ± Ø¨Ù‡ ÙØ±Ø¯ Ø§Ø² ØªØ±Ú©ÛŒØ¨ ID Ù¾Ø³Øª Ø§ØµÙ„ÛŒ Ùˆ URL Ø¢ÛŒØªÙ… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ….
        # Ø§ÛŒÙ† Ú©Ø§Ø± Ø§Ø² ØªØ¯Ø§Ø®Ù„ IDÙ‡Ø§ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
        combined_string = f"{base_id}-{item_url}"
        return hashlib.sha256(combined_string.encode()).hexdigest()

    def _normalize_post_data(self, entry: ET.Element, subreddit_name: str) -> Optional[Dict[str, Any]]: # Any Ø¨Ø±Ø§ÛŒ Ø§Ù†Ø¹Ø·Ø§Ùâ€ŒÙ¾Ø°ÛŒØ±ÛŒ Ø¨ÛŒØ´ØªØ±
        """
        ÛŒÚ© ØªØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÛŒÚ© Ø¢ÛŒØªÙ… RSS Ø¨Ù‡ ÙØ±Ù…Øª Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ Ù¾Ø±ÙˆÚ˜Ù‡.
        Ø§ÛŒÙ† Ù†Ø³Ø®Ù‡ Ù…Ø­ØªÙˆØ§ÛŒ HTML Ø±Ø§ Ø¨Ø±Ø§ÛŒ ÛŒØ§ÙØªÙ† Ù„ÛŒÙ†Ú© Ø§ØµÙ„ÛŒØŒ ØªØµÙˆÛŒØ± Ùˆ ØªÙˆØ¶ÛŒØ­Ø§Øª ØªØ¬Ø²ÛŒÙ‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
        """
        try:
            ns = {'atom': 'http://www.w3.org/2005/Atom'}
            title_element = entry.find('atom:title', ns)
            content_element = entry.find('atom:content', ns)
            id_element = entry.find('atom:id', ns)

            if title_element is None or content_element is None or id_element is None:
                logger.debug(f"Ù¾Ø³Øª RSS Ù†Ø§Ù‚Øµ Ø¯Ø± Ø³Ø§Ø¨â€ŒØ±Ø¯ÛŒØª {subreddit_name} ÛŒØ§ÙØª Ø´Ø¯ (Ø¹Ù†ÙˆØ§Ù†ØŒ Ù…Ø­ØªÙˆØ§ ÛŒØ§ ID Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª).")
                return None

            raw_title = title_element.text
            post_id = id_element.text
            
            # ØªØ¬Ø²ÛŒÙ‡ Ù…Ø­ØªÙˆØ§ÛŒ HTML Ø¨Ø§ BeautifulSoup Ø¨Ø±Ø§ÛŒ ÛŒØ§ÙØªÙ† Ù„ÛŒÙ†Ú© Ø§ØµÙ„ÛŒØŒ ØªØµÙˆÛŒØ± Ùˆ ØªÙˆØ¶ÛŒØ­Ø§Øª
            soup = BeautifulSoup(content_element.text, 'html.parser')
            link_tag = soup.find('a', string='[link]') # Ø¨Ù‡ Ø¯Ù†Ø¨Ø§Ù„ ØªÚ¯ <a> Ø¨Ø§ Ù…ØªÙ† '[link]' Ù…ÛŒâ€ŒÚ¯Ø±Ø¯ÛŒÙ…
            if not link_tag or 'href' not in link_tag.attrs:
                logger.debug(f"Ù„ÛŒÙ†Ú© Ø§ØµÙ„ÛŒ '[link]' Ø¯Ø± Ù¾Ø³Øª '{raw_title}' Ø§Ø² Ø³Ø§Ø¨â€ŒØ±Ø¯ÛŒØª {subreddit_name} ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                return None # Ø§Ú¯Ø± Ù„ÛŒÙ†Ú© Ø§ØµÙ„ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯ØŒ Ù¾Ø³Øª Ø±Ø§ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ù…ÛŒâ€ŒÚ¯ÛŒØ±ÛŒÙ…
            
            url = link_tag['href']
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªÙˆØ¶ÛŒØ­Ø§Øª (Ù…ØªÙ† Ø§ØµÙ„ÛŒ Ù¾Ø³Øª)
            description_tag = soup.find('div', class_='md') # Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ù…Ø­ØªÙˆØ§ÛŒ Markdown Ø¯Ø± Ø§ÛŒÙ† ØªÚ¯ Ø§Ø³Øª
            description = description_tag.get_text(strip=True) if description_tag else ""

            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªØµÙˆÛŒØ± (Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯)
            image_tag = soup.find('img', src=True)
            image_url = image_tag['src'] if image_tag else None

            # --- Ø¨Ù‡Ø¨ÙˆØ¯ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ø§Ù… ÙØ±ÙˆØ´Ú¯Ø§Ù‡ ---
            store = 'other' # Ù…Ù‚Ø¯Ø§Ø± Ù¾ÛŒØ´â€ŒÙØ±Ø¶
            
            # 1. ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø² Ø¨Ø±Ø§Ú©Øª Ø¯Ø± Ø¹Ù†ÙˆØ§Ù†
            store_platform_match = re.search(r'\[([^\]]+)\]', raw_title)
            if store_platform_match:
                platform_str = store_platform_match.group(1).strip().lower()

                if "steam" in platform_str:
                    store = "steam"
                elif "epic games" in platform_str or "epicgames" in platform_str:
                    store = "epic games"
                elif "gog" in platform_str:
                    store = "gog"
                elif "xbox" in platform_str:
                    store = "xbox"
                elif "ps" in platform_str or "playstation" in platform_str:
                    store = "playstation"
                elif "nintendo" in platform_str:
                    store = "nintendo"
                elif "stove" in platform_str:
                    store = "stove"
                elif "indiegala" in platform_str:
                    store = "indiegala"
                elif "itch.io" in platform_str or "itchio" in platform_str:
                    store = "itch.io"
                elif "android" in platform_str or "googleplay" in platform_str or "google play" in platform_str or "apps" in platform_str:
                    if "play.google.com" in url:
                        store = "google play"
                    elif "apps.apple.com" in url:
                        store = "ios app store"
                    else:
                        store = "apps" # ÛŒØ§ 'google play' Ø§Ú¯Ø± Ù…Ø·Ù…Ø¦Ù†ÛŒØ¯ ÙÙ‚Ø· Ú¯ÙˆÚ¯Ù„ Ù¾Ù„ÛŒ Ø§Ø³Øª
                elif "ios" in platform_str or "apple" in platform_str:
                    if "apps.apple.com" in url:
                        store = "ios app store"
                    elif "play.google.com" in url:
                        store = "google play"
                    else:
                        store = "ios app store" # ÛŒØ§ 'apps' Ø¹Ù…ÙˆÙ…ÛŒ
                elif "windows" in platform_str or "mac" in platform_str or "linux" in platform_str:
                    if "store.steampowered.com" in url:
                        store = "steam"
                    elif "epicgames.com" in url:
                        store = "epic games"
                    elif "gog.com" in url:
                        store = "gog"
                    elif "itch.io" in url:
                        store = "itch.io"
                    elif "indiegala.com" in url:
                        store = "indiegala"
                    else:
                        store = "other"
                elif "multi-platform" in platform_str:
                    if "store.steampowered.com" in url:
                        store = "steam"
                    elif "epicgames.com" in url:
                        store = "epic games"
                    elif "gog.com" in url:
                        store = "gog"
                    elif "play.google.com" in url:
                        store = "google play"
                    elif "apps.apple.com" in url:
                        store = "ios app store"
                    else:
                        store = "other"
            
            # 2. Ø§Ú¯Ø± Ù‡Ù†ÙˆØ² Ù†Ø§Ù… ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø¹Ù…ÙˆÙ…ÛŒ Ø¨ÙˆØ¯ØŒ ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø­Ø¯Ø³ Ø²Ø¯Ù† Ø§Ø² URL Ø§ØµÙ„ÛŒ (Ø§Ú¯Ø± Ø§Ø² Ø¨Ø±Ø§Ú©Øª Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ø´Ø¯Ù‡ Ø¨ÙˆØ¯)
            # Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø±Ø§ ÙÙ‚Ø· Ø§Ú¯Ø± store Ù‡Ù†ÙˆØ² 'other' ÛŒØ§ 'apps' ÛŒØ§ 'Ù†Ø§Ù…Ø´Ø®Øµ' Ø§Ø³ØªØŒ Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ….
            if store in ['other', 'Ù†Ø§Ù…Ø´Ø®Øµ', 'apps']:
                if "play.google.com" in url:
                    store = "google play"
                elif "apps.apple.com" in url:
                    store = "ios app store"
                elif "store.steampowered.com" in url:
                    store = "steam"
                elif "epicgames.com" in url:
                    store = "epic games"
                elif "gog.com" in url:
                    store = "gog"
                elif "xbox.com" in url:
                    store = "xbox"
                elif "itch.io" in url:
                    store = "itch.io"
                elif "indiegala.com" in url:
                    store = "indiegala"
                elif "onstove.com" in url:
                    store = "stove"
            
            # ØªÙ…ÛŒØ² Ú©Ø±Ø¯Ù† Ø¹Ù†ÙˆØ§Ù†: Ø­Ø°Ù ØªÙ…Ø§Ù… Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ø¨Ø±Ø§Ú©ØªÛŒ Ùˆ Ø¹Ø¨Ø§Ø±Ø§Øª Ø§Ø¶Ø§ÙÛŒ
            clean_title = re.sub(r'\[[^\]]+\]', '', raw_title).strip()
            clean_title = re.sub(r'\(game\)', '', clean_title, flags=re.IGNORECASE).strip()
            clean_title = re.sub(r'\(\$.*?-> Free\)', '', clean_title, flags=re.IGNORECASE).strip()
            clean_title = re.sub(r'\(\d+%\s*off\)', '', clean_title, flags=re.IGNORECASE).strip()
            clean_title = re.sub(r'\(\s*free\s*\)', '', clean_title, flags=re.IGNORECASE).strip()
            
            # Ø§Ú¯Ø± Ø¹Ù†ÙˆØ§Ù† Ù¾Ø³ Ø§Ø² ØªÙ…ÛŒØ² Ú©Ø±Ø¯Ù† Ø®Ø§Ù„ÛŒ Ø´Ø¯ØŒ Ø§Ø² Ø¹Ù†ÙˆØ§Ù† Ø§ØµÙ„ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… ÛŒØ§ Ø¢Ù† Ø±Ø§ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ù…ÛŒâ€ŒÚ¯ÛŒØ±ÛŒÙ…
            if not clean_title:
                clean_title = raw_title.strip()
                if not clean_title: # Ø§Ú¯Ø± Ø¹Ù†ÙˆØ§Ù† Ø§ØµÙ„ÛŒ Ù‡Ù… Ø®Ø§Ù„ÛŒ Ø¨ÙˆØ¯
                    logger.warning(f"âš ï¸ Ù¾Ø³Øª Ø¨Ø§Ø²ÛŒ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø¨Ø§ Ø¹Ù†ÙˆØ§Ù† Ú©Ø§Ù…Ù„Ø§Ù‹ Ø®Ø§Ù„ÛŒ Ø§Ø² RSS Ø±Ø¯ÛŒØª ({subreddit_name}) Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯. ID: {post_id}")
                    return None

            return {
                "title": clean_title,
                "store": store,
                "url": url,
                "image_url": image_url, # Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù‡
                "description": description, # Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù‡
                "id_in_db": post_id,
                "subreddit": subreddit_name
            }
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù¾Ø³Øª RSS Ø±Ø¯ÛŒØª Ø§Ø² Ø³Ø§Ø¨â€ŒØ±Ø¯ÛŒØª {subreddit_name}: {e}", exc_info=True)
            return None

    def _parse_apphookup_weekly_deals(self, html_content: str, base_post_id: str) -> List[Dict[str, Any]]: # Any Ø¨Ø±Ø§ÛŒ Ø§Ù†Ø¹Ø·Ø§Ùâ€ŒÙ¾Ø°ÛŒØ±ÛŒ Ø¨ÛŒØ´ØªØ±
        """
        Ù…Ø­ØªÙˆØ§ÛŒ HTML Ù¾Ø³Øªâ€ŒÙ‡Ø§ÛŒ 'Weekly deals' Ø§Ø² r/AppHookup Ø±Ø§ ØªØ¬Ø²ÛŒÙ‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
        Ùˆ Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø±Ø§ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
        """
        found_items = []
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù‡Ù…Ù‡ ØªÚ¯â€ŒÙ‡Ø§ÛŒ <a> Ú©Ù‡ Ø¯Ø§Ø±Ø§ÛŒ href Ù‡Ø³ØªÙ†Ø¯ Ùˆ Ø¯Ø± Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§Ùâ€ŒÙ‡Ø§ ÛŒØ§ Ù„ÛŒØ³Øªâ€ŒÙ‡Ø§ Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ù†Ø¯
        for a_tag in soup.find_all('a', href=True):
            parent_text_element = a_tag.find_parent(['p', 'li'])
            if parent_text_element:
                text_around_link = parent_text_element.get_text().lower()
                item_title = a_tag.get_text().strip()
                item_url = a_tag['href']

                # Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ "Ø±Ø§ÛŒÚ¯Ø§Ù†" Ø¯Ø± Ù…ØªÙ† Ø§Ø·Ø±Ø§Ù Ù„ÛŒÙ†Ú©
                is_free = False
                if "free" in text_around_link or "-> 0" in text_around_link or "--> 0" in text_around_link:
                    if "off" in text_around_link and "100% off" not in text_around_link and "free" not in text_around_link:
                        is_free = False
                    else:
                        is_free = True

                if is_free:
                    # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø­Ø¯Ø³ Ø²Ø¯Ù† ÙØ±ÙˆØ´Ú¯Ø§Ù‡ Ø§Ø² URL
                    store = "other"
                    if "apps.apple.com" in item_url:
                        store = "ios app store"
                    elif "play.google.com" in item_url:
                        store = "google play"
                    elif "store.steampowered.com" in item_url:
                        store = "steam"
                    elif "epicgames.com" in item_url:
                        store = "epic games"
                    elif "gog.com" in item_url:
                        store = "gog"
                    elif "xbox.com" in item_url:
                        store = "xbox"
                    elif "itch.io" in item_url:
                        store = "itch.io"
                    elif "indiegala.com" in item_url:
                        store = "indiegala"
                    elif "onstove.com" in item_url:
                        store = "stove"
                    
                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªÙˆØ¶ÛŒØ­Ø§Øª (Ø§Ú¯Ø± Ø¯Ø± Ù†Ø²Ø¯ÛŒÚ©ÛŒ Ù„ÛŒÙ†Ú© Ø¨Ø§Ø´Ø¯)
                    item_description = parent_text_element.get_text(strip=True)
                    # Ø­Ø°Ù Ø¹Ù†ÙˆØ§Ù† Ùˆ Ù„ÛŒÙ†Ú© Ø§Ø² ØªÙˆØ¶ÛŒØ­Ø§Øª
                    item_description = item_description.replace(item_title, '').replace(item_url, '').strip()
                    # Ø§Ú¯Ø± ØªÙˆØ¶ÛŒØ­Ø§Øª Ø®ÛŒÙ„ÛŒ Ú©ÙˆØªØ§Ù‡ Ø¨ÙˆØ¯ØŒ Ø§Ø² Ø¹Ù†ÙˆØ§Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
                    if len(item_description) < 20:
                        item_description = item_title # Fallback to title if description is too short

                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªØµÙˆÛŒØ± (Ø§Ú¯Ø± Ø¯Ø± Ù†Ø²Ø¯ÛŒÚ©ÛŒ Ù„ÛŒÙ†Ú© Ø¨Ø§Ø´Ø¯)
                    item_image_tag = parent_text_element.find('img', src=True)
                    item_image_url = item_image_tag['src'] if item_image_tag else None
                    
                    if item_title:
                        found_items.append({
                            "title": item_title,
                            "store": store,
                            "url": item_url,
                            "image_url": item_image_url, # Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù‡
                            "description": item_description, # Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù‡
                            "id_in_db": self._generate_unique_id(base_post_id, item_url),
                            "subreddit": "AppHookup"
                        })
                        logger.debug(f"âœ… Ø¢ÛŒØªÙ… Ø±Ø§ÛŒÚ¯Ø§Ù† Ø¯Ø§Ø®Ù„ÛŒ Ø§Ø² AppHookup ÛŒØ§ÙØª Ø´Ø¯: {item_title} (URL: {item_url})")
                    else:
                        logger.warning(f"âš ï¸ Ø¢ÛŒØªÙ… Ø±Ø§ÛŒÚ¯Ø§Ù† Ø¯Ø§Ø®Ù„ÛŒ Ø¨Ø§ Ø¹Ù†ÙˆØ§Ù† Ø®Ø§Ù„ÛŒ Ø§Ø² AppHookup Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯. URL: {item_url}")
            
        return found_items

    async def fetch_free_games(self) -> List[Dict[str, Any]]: # Any Ø¨Ø±Ø§ÛŒ Ø§Ù†Ø¹Ø·Ø§Ùâ€ŒÙ¾Ø°ÛŒØ±ÛŒ Ø¨ÛŒØ´ØªØ±
        """
        ÙÛŒØ¯ RSS Ø³Ø§Ø¨â€ŒØ±Ø¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡ Ø±Ø§ Ø¨Ø±Ø§ÛŒ ÛŒØ§ÙØªÙ† Ø¨Ø§Ø²ÛŒâ€ŒÙ‡Ø§ÛŒ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø§Ø³Ú©Ù† Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
        """
        logger.info("ğŸš€ Ø´Ø±ÙˆØ¹ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø¯Ø±ÛŒØ§ÙØª Ø¨Ø§Ø²ÛŒâ€ŒÙ‡Ø§ÛŒ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø§Ø² ÙÛŒØ¯ RSS Ø±Ø¯ÛŒØª...")
        free_games_list = []
        processed_ids = set()

        try:
            for subreddit_name, url in self.rss_urls.items():
                logger.info(f"Ø¯Ø± Ø­Ø§Ù„ Ø§Ø³Ú©Ù† ÙÛŒØ¯ RSS: {url} (Ø³Ø§Ø¨â€ŒØ±Ø¯ÛŒØª: {subreddit_name})...")
                async with aiohttp.ClientSession() as session:
                    headers = {'User-agent': 'GameBeaconBot/1.0'}
                    async with session.get(url, headers=headers) as response:
                        if response.status != 200:
                            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ÙÛŒØ¯ {url}: Status {response.status}")
                            continue
                        
                        rss_content = await response.text()
                        root = ET.fromstring(rss_content)
                        
                        ns = {'atom': 'http://www.w3.org/2005/Atom'}
                        for entry in root.findall('atom:entry', ns):
                            title_element = entry.find('atom:title', ns)
                            content_element = entry.find('atom:content', ns)
                            id_element = entry.find('atom:id', ns)

                            if title_element is None or content_element is None or id_element is None:
                                logger.debug(f"Ù¾Ø³Øª RSS Ù†Ø§Ù‚Øµ Ø¯Ø± Ø³Ø§Ø¨â€ŒØ±Ø¯ÛŒØª {subreddit_name} (Ø¹Ù†ÙˆØ§Ù†ØŒ Ù…Ø­ØªÙˆØ§ ÛŒØ§ ID Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª).")
                                continue

                            title_lower = title_element.text.lower()
                            post_id = id_element.text

                            is_free_game = False
                            
                            if subreddit_name == 'FreeGameFindings':
                                if "(game)" in title_lower:
                                    if "off" in title_lower and "100% off" not in title_lower:
                                        is_free_game = False
                                    else:
                                        is_free_game = True
                                
                                if "free" in title_lower or "100% off" in title_lower or "100% discount" in title_lower:
                                    is_free_game = True
                            
                            elif subreddit_name == 'googleplaydeals' or subreddit_name == 'AppHookup':
                                keywords = ['free', '100% off', '100% discount']
                                if any(keyword in title_lower for keyword in keywords):
                                    is_free_game = True
                                
                                if subreddit_name == 'AppHookup' and ("weekly" in title_lower and ("deals post" in title_lower or "app deals post" in title_lower or "game deals post" in title_lower)):
                                    logger.info(f"ğŸ” Ù¾Ø³Øª 'Weekly Deals' Ø§Ø² AppHookup Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯: {title_element.text}. Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø±Ø±Ø³ÛŒ Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø®Ù„ÛŒ...")
                                    weekly_items = self._parse_apphookup_weekly_deals(content_element.text, post_id)
                                    for item in weekly_items:
                                        if item['id_in_db'] not in processed_ids:
                                            free_games_list.append(item)
                                            processed_ids.add(item['id_in_db'])
                                            logger.info(f"âœ… Ø¢ÛŒØªÙ… Ø±Ø§ÛŒÚ¯Ø§Ù† Ø§Ø² Ù„ÛŒØ³Øª 'Weekly Deals' ({item['subreddit']}) ÛŒØ§ÙØª Ø´Ø¯: {item['title']} (ÙØ±ÙˆØ´Ú¯Ø§Ù‡: {item['store']})")
                                    continue

                            else: # Ø¨Ø±Ø§ÛŒ Ø³Ø§ÛŒØ± Ø³Ø§Ø¨â€ŒØ±Ø¯ÛŒØªâ€ŒÙ‡Ø§ (Ù…Ø«Ù„ GameDeals)
                                keywords = ['free', '100% off', '100% discount']
                                if any(keyword in title_lower for keyword in keywords):
                                    is_free_game = True

                            if is_free_game:
                                normalized_game = self._normalize_post_data(entry, subreddit_name)
                                if normalized_game and normalized_game['id_in_db'] not in processed_ids:
                                    if normalized_game['title'].strip():
                                        free_games_list.append(normalized_game)
                                        processed_ids.add(normalized_game['id_in_db'])
                                        logger.info(f"âœ… Ù¾Ø³Øª Ø¨Ø§Ø²ÛŒ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø§Ø² RSS Ø±Ø¯ÛŒØª ({normalized_game['subreddit']}) ÛŒØ§ÙØª Ø´Ø¯: {normalized_game['title']} (ÙØ±ÙˆØ´Ú¯Ø§Ù‡: {normalized_game['store']})")
                                    else:
                                        logger.warning(f"âš ï¸ Ù¾Ø³Øª Ø¨Ø§Ø²ÛŒ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø¨Ø§ Ø¹Ù†ÙˆØ§Ù† Ø®Ø§Ù„ÛŒ Ø§Ø² RSS Ø±Ø¯ÛŒØª ({subreddit_name}) Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯. ID: {normalized_game['id_in_db']}")
                                else:
                                    logger.debug(f"â„¹ï¸ Ù¾Ø³Øª '{title_element.text}' Ø§Ø² {subreddit_name} ÛŒØ§ Ø§Ø² Ù‚Ø¨Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡ Ø¨ÙˆØ¯ ÛŒØ§ Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù†Ø´Ø¯.")
                            else:
                                logger.debug(f"ğŸ” Ù¾Ø³Øª '{title_element.text}' Ø§Ø² {subreddit_name} Ø´Ø±Ø§ÛŒØ· 'Ø¨Ø§Ø²ÛŒ Ø±Ø§ÛŒÚ¯Ø§Ù†' Ø±Ø§ Ù†Ø¯Ø§Ø´Øª Ùˆ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯.")

        except Exception as e:
            logger.critical(f"ğŸ”¥ ÛŒÚ© Ø®Ø·Ø§ÛŒ Ø¨Ø­Ø±Ø§Ù†ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù†Ø´Ø¯Ù‡ Ø¯Ø± Ù…Ø§Ú˜ÙˆÙ„ Reddit (RSS) Ø±Ø® Ø¯Ø§Ø¯: {e}", exc_info=True)
            
        if not free_games_list:
            logger.info("â„¹ï¸ Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ù¾Ø³Øª Ø¨Ø§Ø²ÛŒ Ø±Ø§ÛŒÚ¯Ø§Ù† Ø¬Ø¯ÛŒØ¯ÛŒ Ø¯Ø± ÙÛŒØ¯Ù‡Ø§ÛŒ RSS Ø±Ø¯ÛŒØª ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            
        return free_games_list
